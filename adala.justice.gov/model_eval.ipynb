{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e0dc516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from lime import lime_text\n",
    "import shap\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c004269",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ychafiqui/moroccan_law_classif_arabert2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82211cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = 0 if torch.cuda.is_available() else -1\n",
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "431b80e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"articles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cb61137",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2a85d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert the text column to a list\n",
    "texts = test[\"article_text\"].tolist()\n",
    "\n",
    "# 2. Run the pipeline on the list with a defined batch_size\n",
    "# The pipeline returns a list of dictionaries\n",
    "results = pipe(texts, batch_size=512, truncation=True)\n",
    "\n",
    "# 3. Extract the labels and assign back to the DataFrame\n",
    "test[\"model_prediction\"] = [res['label'] for res in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f32aedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8410210479175997\n",
      "Precision: 0.8448237014679889\n",
      "Recall: 0.8410210479175997\n",
      "F1 Score: 0.8418880335410293\n"
     ]
    }
   ],
   "source": [
    "# evaluation metrics\n",
    "y_true = test['merged_category']\n",
    "y_pred = test['model_prediction']\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2fae0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dca3acf11fa4368b0abff7822b285ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ychaf\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ychaf\\.cache\\huggingface\\hub\\models--ychafiqui--moroccan_law_qst_classif_arabert2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eae6c888ea24558a20a75053c61644f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a42dc8fc13434e9d3dfdd35b59ac2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38d5364093de4944a8044ef408f275fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9523cdc221f24c4db2fa30507d2096a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "825ffffe1be04dc4b351046b5cd5b90c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.48G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"ychafiqui/moroccan_law_qst_classif_arabert2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47163559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "Device set to use 0\n",
      "The model 'BertForSequenceClassification' is not supported for text-classification. Supported models are ['PeftModelForSequenceClassification', 'TFAlbertForSequenceClassification', 'TFBartForSequenceClassification', 'TFBertForSequenceClassification', 'TFCamembertForSequenceClassification', 'TFConvBertForSequenceClassification', 'TFCTRLForSequenceClassification', 'TFDebertaForSequenceClassification', 'TFDebertaV2ForSequenceClassification', 'TFDistilBertForSequenceClassification', 'TFElectraForSequenceClassification', 'TFEsmForSequenceClassification', 'TFFlaubertForSequenceClassification', 'TFFunnelForSequenceClassification', 'TFGPT2ForSequenceClassification', 'TFGPT2ForSequenceClassification', 'TFGPTJForSequenceClassification', 'TFLayoutLMForSequenceClassification', 'TFLayoutLMv3ForSequenceClassification', 'TFLongformerForSequenceClassification', 'TFMistralForSequenceClassification', 'TFMobileBertForSequenceClassification', 'TFMPNetForSequenceClassification', 'TFOpenAIGPTForSequenceClassification', 'TFRemBertForSequenceClassification', 'TFRobertaForSequenceClassification', 'TFRobertaPreLayerNormForSequenceClassification', 'TFRoFormerForSequenceClassification', 'TFTapasForSequenceClassification', 'TFTransfoXLForSequenceClassification', 'TFXLMForSequenceClassification', 'TFXLMRobertaForSequenceClassification', 'TFXLNetForSequenceClassification'].\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, framework=\"tf\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fa721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"generated_questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d70af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5b1550",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"model_prediction\"] = test[\"generated_question\"].apply(lambda x: pipe(x)[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4dceae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.766\n",
      "Precision: 0.7848406697276293\n",
      "Recall: 0.766\n",
      "F1 Score: 0.7669954796045069\n"
     ]
    }
   ],
   "source": [
    "# evaluation metrics\n",
    "y_true = test['merged_category']\n",
    "y_pred = test['model_prediction']\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
